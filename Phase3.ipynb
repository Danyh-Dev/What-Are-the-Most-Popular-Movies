{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34d5fc67-af6c-4c50-96c4-ac3fb146f310",
   "metadata": {},
   "source": [
    "# Can We Predict a Movie's Popularity (Votes) Based on Its Features Like Genre, Year, and Runtime?\n",
    "\n",
    "In this phase, our goal is to answer the question:  \n",
    "**\"Can we predict a movie's popularity (votes) based on its features like genre, year, and runtime?\"**\n",
    "\n",
    "The target variable is the **number of votes** that the movie received. The features we will rely on are:\n",
    "- **Year**: The year the movie was released.\n",
    "- **Runtime**: The duration of the movie in minutes.\n",
    "- **Genres**: The columns that represent the genres of the movie (e.g., Action, Comedy).\n",
    "\n",
    "The dataset has been split into training and testing sets, using 80% of the data for training and 20% for testing.\n",
    "\n",
    "The objective is to select the model that provides the best accuracy in predicting a movie's popularity based on its features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89083b9-3f0c-4b42-a29e-99ef250a56f3",
   "metadata": {},
   "source": [
    "## Step 1: Data Preparation and Feature Selection\n",
    "\n",
    "In this step, we load the cleaned dataset, select only the relevant features (such as runtime, release year, and movie genres), and prepare the data by handling any missing values. We then split the data into training and testing sets to be used later in the modeling phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b9034803-548b-4707-8b42-932cdc77caca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year                                                          0\n",
      "Runtime                                                       0\n",
      "Genre_Action, Adventure, Animation, Drama                     0\n",
      "Genre_Action, Adventure, Animation, Drama, Family, Fantasy    0\n",
      "Genre_Action, Adventure, Drama                                0\n",
      "                                                             ..\n",
      "Genre_War, Drama, Thriller, Mystery                           0\n",
      "Genre_War, History, Thriller                                  0\n",
      "Genre_War, History, Thriller, Drama                           0\n",
      "Genre_Western                                                 0\n",
      "Votes                                                         0\n",
      "Length: 276, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('Primary_Processed_Data.csv')\n",
    "\n",
    "# Define the target column and basic features\n",
    "target_column = 'Votes'\n",
    "basic_features = ['Year', 'Runtime']\n",
    "\n",
    "# Automatically extract all genre columns (columns starting with 'Genre_')\n",
    "genre_columns = [col for col in df.columns if col.startswith('Genre_')]\n",
    "\n",
    "# Combine all selected features + target into a new dataframe\n",
    "selected_columns = basic_features + genre_columns + [target_column]\n",
    "df_selected = df[selected_columns].copy()\n",
    "\n",
    "# Check for missing values\n",
    "print(df_selected.isnull().sum())\n",
    "\n",
    "# Drop rows with missing values (to avoid training issues)\n",
    "df_selected.dropna(inplace=True)\n",
    "\n",
    "# Split the data into features (X) and target (y)\n",
    "X = df_selected.drop(target_column, axis=1)\n",
    "y = df_selected[target_column]\n",
    "\n",
    "# Split data into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af68d264-1741-4d85-8709-85f56143d46f",
   "metadata": {},
   "source": [
    "## Step 2: Building and Evaluating the Baseline Model\n",
    "\n",
    "In this step, we build a simple baseline model using **Linear Regression**.  \n",
    "This model will serve as a benchmark to compare more advanced models later.  \n",
    "We train the model on the training set, make predictions on the test set, and evaluate performance using MAE, RMSE, and R² Score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2a8d3ec7-e89e-402d-be83-564f8708de82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Model - Linear Regression:\n",
      "MAE: 1311549886.845346\n",
      "RMSE: 3290435998.4628363\n",
      "R² Score: -2.640036316040506e+20\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Build the baseline model using Linear Regression\n",
    "baseline_model = LinearRegression()\n",
    "baseline_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_baseline = baseline_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mae = mean_absolute_error(y_test, y_pred_baseline)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred_baseline))\n",
    "r2 = r2_score(y_test, y_pred_baseline)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Baseline Model - Linear Regression:\")\n",
    "print(f\"MAE: {mae}\")\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"R² Score: {r2}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f157c869-40eb-405c-a1c5-b48a42239cc7",
   "metadata": {},
   "source": [
    "## Step 3: Building and Evaluating the Random Forest Regressor Model\n",
    "\n",
    "In this step, we build the **Random Forest Regressor** model.  \n",
    "Random Forest is an ensemble learning method that creates multiple decision trees and merges them together to get a more accurate prediction.  \n",
    "We train the model, make predictions on the test set, and evaluate its performance using MAE, RMSE, and R² Score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a5297055-de61-42e1-a122-c204ea17ac44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest Regressor:\n",
      "MAE: 0.12826966950409097\n",
      "RMSE: 0.20482426726470995\n",
      "R² Score: -0.0229768956421863\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Build the Random Forest Regressor model\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mae_rf = mean_absolute_error(y_test, y_pred_rf)\n",
    "rmse_rf = np.sqrt(mean_squared_error(y_test, y_pred_rf))\n",
    "r2_rf = r2_score(y_test, y_pred_rf)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"\\nRandom Forest Regressor:\")\n",
    "print(f\"MAE: {mae_rf}\")\n",
    "print(f\"RMSE: {rmse_rf}\")\n",
    "print(f\"R² Score: {r2_rf}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5fd1486-114c-48ee-9280-b3c4334992e4",
   "metadata": {},
   "source": [
    "## Step 4: Building and Evaluating the Gradient Boosting Regressor Model\n",
    "\n",
    "In this step, we build the **Gradient Boosting Regressor** model.  \n",
    "Gradient Boosting is an ensemble learning technique that builds the model in a sequential manner by focusing on the errors made by the previous models.  \n",
    "We train the model, make predictions, and evaluate its performance using MAE, RMSE, and R² Score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a70a0399-5b43-4ecc-917f-c4a94a1ffe3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gradient Boosting Regressor:\n",
      "MAE: 0.13702244344263556\n",
      "RMSE: 0.1940174246397845\n",
      "R² Score: 0.08212302358981927\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# Build the Gradient Boosting Regressor model\n",
    "gb_model = GradientBoostingRegressor(random_state=42)\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_gb = gb_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mae_gb = mean_absolute_error(y_test, y_pred_gb)\n",
    "rmse_gb = np.sqrt(mean_squared_error(y_test, y_pred_gb))\n",
    "r2_gb = r2_score(y_test, y_pred_gb)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"\\nGradient Boosting Regressor:\")\n",
    "print(f\"MAE: {mae_gb}\")\n",
    "print(f\"RMSE: {rmse_gb}\")\n",
    "print(f\"R² Score: {r2_gb}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4b6857-e84f-481c-b00e-d000c0488e99",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### **Model Results and Evaluation**\n",
    "\n",
    "#### **1- Baseline Model: Linear Regression**  \n",
    "- **R² Score:** -2.64e+20  \n",
    "- **Reason for exclusion:**  \n",
    "  The baseline model performed extremely poorly, with a highly negative **R² Score**, indicating that it does not fit the data well or explain the variance in the target variable.\n",
    "\n",
    "\n",
    "#### **2- Random Forest Regressor**  \n",
    "- **R² Score:** -0.023  \n",
    "- **Reason for exclusion:**  \n",
    "  Although the model produced relatively low **MAE** and **RMSE**, the **R² Score** was still negative. This suggests that the model fails to effectively explain the target variable and is not reliable for accurate predictions.\n",
    "\n",
    "\n",
    "\n",
    "#### **3- Gradient Boosting Regressor**  \n",
    "- **R² Score:** 0.082  \n",
    "- **Reason for selection:**  \n",
    "  This model achieved the best performance among all three, with a **positive R² Score**, indicating some ability to explain the variance in the target variable. While the score is modest, it still outperforms the other models and shows potential for making more accurate predictions. The **MAE** and **RMSE** were also within a reasonable range.\n",
    "\n",
    "\n",
    "###  **Best Model: Gradient Boosting Regressor**  \n",
    "The **Gradient Boosting Regressor** was selected as the best model because it was the only one to achieve a **positive R² Score**, demonstrating a better fit to the data and more reliable predictive performance compared to the other models.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91258850-fdae-4f87-85f2-da0605ec5d25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
